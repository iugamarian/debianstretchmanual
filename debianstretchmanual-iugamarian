#### Very good applications

# https://mate-desktop.org/

su -
apt install -y unar youtube-dl mc git guvcview mediainfo-gui mpv ffmpeg

#### Upscale 720p movie to 1080p movie fast but large so you can correctly see image subtitles in mpv

# https://superuser.com/questions/714804/converting-video-from-1080p-to-720p-with-smallest-qualiti-loss-using-ffmpeg
# https://trac.ffmpeg.org/wiki/Scaling%20(resizing)%20with%20ffmpeg

ffmpeg -i movie.mp4 -vf scale=1920:1080 -c:v libx264 -crf 0 -preset veryfast -c:a copy movie.mkv

#### Record webcam raw audio and video

# Sound Preferences -> Input -> select C910

# View that audio input is working:

pavucontrol

# https://wiki.archlinux.org/index.php/Webcam_setup#Webcam_configuration
# https://stackoverflow.com/questions/26108643/setting-frame-rate-on-logitech-c210-webcam-in-c-on-raspberry-pi-using-v4l2
# Webcam Logitech HD Pro Webcam C910 needs 640x480 to have high frame rate

# https://wiki.archlinux.org/index.php/FFmpeg#Recording_webcam
# https://raspberrypi.stackexchange.com/questions/3194/dump-video-from-webcam-to-file
# Press CTRL+C to stop recording

#ffmpeg -f v4l2 -video_size 640x480 -i /dev/video0 -f alsa -i default -c:v copy -c:a copy output.mkv
ffmpeg -f v4l2 -video_size 640x480 -i /dev/video0 -f alsa -i default -c:v libx264 -crf 0 -preset ultrafast -c:a libmp3lame -aq 320k output.mkv

# https://wjwoodrow.wordpress.com/2013/02/04/correcting-for-audiovideo-sync-issues-with-the-ffmpeg-programs-itsoffset-switch/
# Audio is 850ms before video on Logitech HD Pro Webcam C910 sometimes

#ffmpeg -i output.mkv -itsoffset 0.850 -i output.mkv -vcodec libx264 -crf 18 -acodec libmp3lame -aq 320k -map 0:0 -map 1:1 output-correct.mkv
ffmpeg -i output.mkv -itsoffset 0.850 -i output.mkv -vcodec copy -acodec copy -map 0:0 -map 1:1 output-correct.mkv

# One hour on Logitech HD Pro Webcam C910 takes 63 GB so about 18 MB/s. With lossless encoding ultrafast 17 GB.
# https://superuser.com/questions/486325/lossless-universal-video-format
# https://trac.ffmpeg.org/wiki/Encode/H.264
# https://trac.ffmpeg.org/wiki/Encode/MP3


#### Modify your prompt in .bashrc with a help site

# http://ezprompt.net/

# I modify to add 24hr time w/ seconds, good to see how much time commands take

if [ "$color_prompt" = yes ]; then
    PS1='${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$\t\$ '
else
    PS1='${debian_chroot:+($debian_chroot)}\u@\h:\w\$\t\$ '
fi


#### Write, manage and understand C programs if you want to

# http://sillybytes.net/2016/06/how-to-write-c-in-2016.html

# Example 1 executable file is 71 bytes, use printf:
===================================================================================================
#include <stdio.h>

int main( )
{
        printf("hello, world\n");
}
===================================================================================================
# https://en.wikipedia.org/wiki/%22Hello,_World!%22_program
# https://stackoverflow.com/questions/1761051/difference-between-n-and-r
# https://en.wikipedia.org/wiki/Newline
# https://stackoverflow.com/questions/43369505/how-to-write-hello-world-without-using-header-file-in-c

# Example 2 executable file is 105 bytes, avoid using printf:
===================================================================================================
#include <stdio.h>

int main( )
{
        char *p = "hello, world\n";
        while (*p)
        {
                putchar(*p);
                p++;
        }
}
===================================================================================================
# *p is a pointer - a memory address where [hello, world\n] is written
# https://en.wikipedia.org/wiki/Pointer_%28computer_programming%29


#### Run Windows programs

# Taken from here
# https://wiki.debian.org/Wine

dpkg --add-architecture i386 && sudo apt update
apt install -y wine-development wine32-development wine64-development libwine-development libwine-development:i386 fonts-wine
# Quake 4 Demo works very well on amdgpu AMD RX480, no WIN32 prefix required,
# no extra dll's or configurations required except winecfg -> select Windows 7


#### Connect to wifi using only terminal

# Taken from here:
# https://askubuntu.com/questions/833905/how-can-i-connect-to-a-specific-bssid

# Show wireless networks with quality bars:
nmcli -f in-use,ssid,bssid,signal,bars  dev wifi
# Connect to one of the indicated bssid XX:XX:XX:XX:XX:XX :
nmcli d wifi connect XX:XX:XX:XX:XX:XX password "mypassword"
# Security concern - password remains in .bash_history

# Or use nmtui for ncurses menu access to Network Manager


#### Software Raid with mdadm

# https://wiki.debian.org/SoftwareRAID


#### Fix “E: unable to locate package” Error in Debian 9

# https://www.tecmint.com/fix-unable-to-locate-package-error-in-debian-9/


#### Get Started With GNUPlot

# https://www.howtoforge.com/tutorial/get-started-with-gnuplot/


#### Low-Level Graphics on Linux (no dependency)

# http://betteros.org/tut/graphics1.php


#### Developing and maintaining Debian has some advantages

# https://wiki.debian.org/MemberBenefits


#### Build and install Open Broadcaster Software

# Become root:

su -

===================================================================================================
# FFmpeg in Debian Stretch, taken from here:
# https://www.reddit.com/r/debian/comments/69o4l4/i_am_having_trouble_building_obsstudio_on_debian_8/

apt install -y libswscale-dev libswresample-dev libavcodec-dev libavdevice-dev libavformat-dev
===================================================================================================

# Taken from here:
# https://github.com/jp9000/obs-studio/wiki/Install-Instructions#linux-install-directions

apt install -y libx11-dev libgl1-mesa-dev libpulse-dev libxcomposite-dev libxinerama-dev libv4l-dev libudev-dev libfreetype6-dev libfontconfig-dev qtbase5-dev 
libqt5x11extras5-dev libx264-dev libxcb-xinerama0-dev libxcb-shm0-dev libjack-jackd2-dev libcurl4-openssl-dev

# Become a user:

exit
git clone https://github.com/jp9000/obs-studio.git
cd obs-studio
mkdir build && cd build
cmake -DUNIX_STRUCTURE=1 -DCMAKE_INSTALL_PREFIX=/usr ..
make -j4
pwd
su -
cd ......build folder from previows pwd.......
sudo checkinstall --pkgname=obs-studio --fstrans=no --backup=no --pkgversion="$(date +%Y%m%d)-git" --deldoc=yes

# Become a user:

exit
whoami

# Become root:

su -
cd ......build folder from previous pwd.......
chown -R ...user from previous whoami... *
chgrp -R ...user from previous whoami... *
dpkg -i *.deb

# Become a user:

exit

# Save all buffers to disk:

sync


#### Debian Stretch Live with persistence

# See here included file debian-stretch-live-with-persistence for EFI and
# debian-stretch-live-with-persistence-for-old-laptop for no EFI, old BIOS.
# This manual explains persistence:
# http://debian-live.alioth.debian.org/live-manual/stable/manual/html/live-manual.en.html


#### Boot on old laptop with BIOS

# If BIOS can't boot properly from USB, not fast or not found, use Plop Boot Manager from:
# https://www.plop.at/en/bootmanagers.html

# Write Plop Boot Manager to CD and boot from it with installed or live Debian on USB, select USB
# Very useful if BIOS does not have Boot from USB option.
# When boot is too slow, USB 1.1 instead of USB 2.0, it may be a hardware issue:
# Ground loop between GND of laptop and GND of external harddisk. Check by booting laptop on battery only.



#### W A R N I N G S ! ! !

---in vi or vim doing a right click and paste makes TAB's be incorrect so on OpenWRT over ssh
    you brick the router and need to connect to serial interface to unbrick - issue a "mtd erase rootfs_data"
    https://forum.openwrt.org/viewtopic.php?id=25421
    Solution: use "nano" or "cat ... EOF" to paste in terminal, through ssh
    
---"unrar" is non-free, so on Raspbian Stretch you only have the source from non-free, no binary
    Solution: install free "unar", it is intergated in graphical archivers, works as best as "unrar"
    Yes, without the r in it's name.

---when a full screen graphical application hangs, you can't do anything on the computer
    Solution: 1) press computer's the power button for a short time, then cancel, then kill application from System Monitor
              2) CTRL+ALT+F1 through CTRL+ALT+F6 login as root or as user, you can issue commands, best one would be reboot
                 You can return to the graphical desktop with ALT+F7 or CTRL+ALT+F7. When in text mode just ALT needed,
                 in grapgical mode CTRL+ALT is mandatory. If you know the name of the hanged application you can kill it
                 by doing textually "killall application", already available on Debian Stretch from the "psmisc" package

---Linux hangs when a (usually erronated) process asks for more memory than the computer has
    Solution: In a .conf file in /etc/sysctl.d write (swap more, 32MB only for kernel, less file data in RAM):
        vm.swappiness = 60
        vm.min_free_kbytes = 32768
        vm.vfs_cache_pressure = 300

---on a computer power outage you can lose unwritten data and there is a lot of it by default
    Solution: In a .conf file in /etc/sysctl.d write (max buffer 128 MB, write all that's older than 6 seconds):
        vm.dirty_bytes = 134217728
        vm.dirty_background_bytes = 134217728
        vm.dirty_writeback_centisecs = 600
        vm.dirty_expire_centisecs = 600

or for OpenWRT or LEDE full /etc/sysctl.conf

https://www.pcsuggest.com/transmission-openwrt-torrent-downloader/

vm.vfs_cache_pressure=200
vm.min_free_kbytes=4096
vm.overcommit_memory=2
vm.overcommit_ratio=60
vm.swappiness=95
vm.dirty_bytes = 2097152
vm.dirty_background_bytes = 2097152
vm.dirty_writeback_centisecs = 600
vm.dirty_expire_centisecs = 600



---apt or web browser hangs on the internet for IPV6 addresses, this means the ISP does not allow them
    Solution: In a .conf file in /etc/sysctl.d write (disable ipv6):
        net.ipv6.conf.all.disable_ipv6 = 1
        net.ipv6.conf.default.disable_ipv6 = 1
 
 ---web browser does not refresh properly, keeps old page when F5 is pressed
    Solution: Press CTRL+F5 or with browser closed delete from home folder: .mozilla and .cache/mozilla
        To see hidden .files in most graphical file managers press CTRL+H and press again to deactivate.

---/tmp is not actually in tmpfs and is slow for multiple operations
    Solution:
        # https://github.com/debian-pi/raspbian-ua-netinst/issues/210
        # https://askubuntu.com/questions/432699/what-is-the-t-letter-in-the-output-of-ls-ld-tmp
        In /etc/fstab add this, then reboot:
        tmpfs           /tmp            tmpfs  nodev,nosuid,mode=1777     0 0

---Firefox is slow, this is mostly because of it's on disk cache (a lot of small writes)
    Solution:
        Make sure /tmp is actually in tmpfs not on disk:
        df -hT
        As the user (not as root), close all Firefox windows and run these commands:
        rm -rf /home/$USER/.cache/mozilla
        ln -s /tmp /home/$USER/.cache/mozilla
        And check that it worked:
        ls -l /home/$USER/.cache
        No reboot required.
        Firefox will remember passwords, bookmarks and history because they are in /home/$USER/.mozilla
        and they slow it down much less than /home/$USER/.cache/mozilla and can continue to stay on disk.
        Firefox creates /home/$USER/.cache/mozilla/firefox/xxx.xxx which now becomes /tmp/firefox/xxx.xxx
        in tmpfs. Other users will get different xxx.xxx so it works for multiple users including root.

---Hard disk has bad blocks and you want to try to repair it without formatting
    Solution:
        # https://askubuntu.com/questions/291570/mark-bad-sectors-on-hard-drive-without-formating/490549#490549
        sudo badblocks -svvn -c 262144 /dev/sdx
        For very old hard disks (under 40 GB) reduce -c number 8 times to 32768 as speed is much lower.
        Or this that works well on hard disk that click a lot, reduces clicking after some more usage:
        # https://askubuntu.com/questions/241944/how-to-fix-the-hard-drive-bad-sector
        dd if=/dev/zero of=/dev/sdx bs=1M 

---Unable to login all of the sudden
    Solution:
        Root partition is full 0 bytes free - use a live CD to delete some files, with ncdu


---Dual boot time with Windows is incorrect
    Solution: Windows writes local time to clock chip, Linux writes UTC time to chip.
    Ubuntu uses localtime from the factory in order to better dualboot. Debian uses UTC. Make Linux use local time:
        https://wiki.archlinux.org/index.php/time
        https://wiki.archlinux.org/index.php/Network_Time_Protocol_daemon
        su -
        timedatectl set-local-rtc 1
        And to syncronize without restarting computer:
        apt install -y ntp
        ntpd -qg
        In a minute the clocks on screen will be updated. -q=quit after -g=set on error, can do max 68 years past or future.
        But the actual hardware clock is not written yet and running programs show bugs in time manasgement (transmission)
        https://www.thegeekstuff.com/2013/08/hwclock-examples/
        https://askubuntu.com/questions/175452/hwclock-not-in-sync-with-system-clock
        hwclock -w -l
        hwclock
        date
        If hwclock is the same as date clock then don't do this also:
        hwclock -w -u
        hwclock
        date
        If hwclock is the same as date clock then don't do this also:
        hwclock --set --date "8/11/2018 23:10:45"
        
        man hwclock
        
        LOCAL vs UTC
       Keeping the Hardware Clock in a local  timescale  causes  inconsistent
       daylight saving time results:

       · If  Linux  is  running during a daylight saving time change, the time
         written to the Hardware Clock will be adjusted for the change.

       · If Linux is NOT running during a daylight  saving  time  change,  the
         time  read  from  the  Hardware  Clock  will  NOT be adjusted for the
         change.

       The Hardware Clock on an ISA compatible system keeps only  a  date  and
       time,  it  has  no  concept of timezone nor daylight saving. Therefore,
       when hwclock is told that it is in local time, it assumes it is in  the
       'correct' local time and makes no adjustments to the time read from it.

       Linux handles daylight saving time changes transparently only when the
       Hardware Clock is kept in the UTC timescale. Doing so is made easy  for
       system  administrators as hwclock uses local time for its output and as
       the argument to the --date option.

       POSIX systems, like Linux, are designed to have the System Clock  oper‐
       ate in the UTC timescale. The Hardware Clock's purpose is to initialize
       the System Clock, so also keeping it in UTC makes sense.

       Linux does, however, attempt to accommodate the Hardware Clock being in
       the local timescale. This is primarily for dual-booting with older ver‐
       sions of MS Windows. From Windows 7 on,  the  RealTimeIsUniversal  reg‐
       istry key is supposed to be working properly so that its Hardware Clock
       can be kept in UTC.


---Printer settings not found, printer not working
    Solution: Debian is fussy about printers for space and security reasons:
        https://www.howtoforge.com/how-to-install-a-canon-printer-on-debian-and-debian-like-systems
        su -
        apt-get install -y cups cups-client foomatic-db
        adduser YOUR_NORMAL_ACCOUNT lpadmin
        Power on and plug your printer, and then browse as user YOUR_NORMAL_ACCOUNT to http://localhost:631/
        Go to the Administration tab and click Add printer
        For Samsung SCX-4216F the ppd driver SCX-4x16 is not good, scroll down and select Samsung-SCX-4216F
        https://debian-handbook.info/browse/stable/sect.config-printing.html
        apt-get install -y system-config-printer
        
---USB enclosure drive not working on motherboard and the other way arround
    Solution: The USB enclosures reported a different sector size than the motherboard,
        and as result the partition tables are interpreted differently:
        https://serverfault.com/questions/764271/cant-mount-sata-drives-when-moved-from-usb-enclosure-to-internal
        I had a similar problem with a 4TB disk that I had moved from a USB enclosure to an internal SATA port.
        Apparently the USB enclosure had reported 4k sectors, and thus I was able to use an old-fashioned MBR
        partition table to create a 4TB ext4 partition. After connecting the disk via SATA, the ext4 partition
        wasn't found any more, apparently because the disk was accessed with 512B sectors now.
        I got it solved with the following steps, using the Testdisk data recovery tool which is available in Ubuntu:
        created a backup of the original partition table (sfdisk -d /dev/sdb > sfdisk-sdb.txt), for safety
        used testdisk /dev/sdb to find the original ext4 file system
        let testdisk write a new MBR partition table to disk
        since MBR table doesn't support 4TB partitions, the ext4 partition still couldn't be mounted, with error
        EXT4-fs (sdb1): bad geometry: block count 976751744 exceeds size of device (536870911 blocks)
        used gdisk /dev/sdb to convert the MBR to GPT format, and write the GPT to disk
        used testdisk /dev/sdb again to find the original ext4 file system (it detected the wrong file system type
        but that didn't matter), and let it write a new GPT table to disk
        used gdisk /dev/sdb to change the incorrectly detected file system type to 8300
        Maybe I just got lucky, but after this procedure the ext4 file system could be mounted as usual.
        fsck -f /dev/sdb1 didn't detect any errors, and blkid /dev/sdb1 and tune2fs /dev/sdb1 gave same results as
        when using the USB enclosure.
        Sector-size issues are becoming quite complex. Until late 2009, the vast majority of hard disks used 512-byte
        sectors, and that was that. In late 2009, disk manufacturers began introducing so-called Advanced Format (AF)
        disks, which use 4096-byte sectors. These first AF disks (and, AFAIK, all AF disks today) present an interface
        to the computer that shows each 4096-byte physical sector as being split up into eight 512-byte logical sectors.
        This conversion enables older tools, including many BIOSes, that were built with 512-byte assumptions, to
        continue to work. I don't know if your disk uses AF or not, but in either case, it almost certainly uses a
        512-byte logical sector size, meaning that the interface to the OS should use 512-byte sectors.
        Complicating matters is certain USB disk enclosures. Some of these enclosures do the reverse of what AF does:
        They take eight disk sectors and bundle them into one new 4096-byte sector. I'm not sure what the reasoning
        is behind this move, but one practical advantage is that disks larger than 2TiB can be used with the old MBR
        partitioning system. One major disadvantage is that a disk partitioned in one of these enclosures can not be
        used directly or in an enclosure that doesn't do this type of translation. Likewise, a disk prepared without
        this translation can't be used when it's transferred into such an enclosure. Note that this problem goes well
        beyond the MBR itself; your disk might identify the first partition as beginning on (512-byte) sector 2048,
        but if your OS were to seek to (4096-byte) sector 2048, it would not find the start of that partition! You've
        run into this problem. As such, your initial thought that it's the USB enclosure's fault is closer to the mark
        than your more recent thought that your motherboard messed it up. I've never heard of a motherboard translating
        sector size in this way. (Some hardware RAID devices do so, though.)
        I don't know of a way to force Linux to adjust its idea of the sector size, but if you have enough disk space,
        doing a low-level disk copy to another disk may help. For instance:

        dd if=/dev/sdb of=~/image.img

        This will copy your disk from /dev/sdb (the USB disk; adjust as necessary) to the file ~/image.img. You can then
        use the following script to mount the image's partitions:

        #!/bin/bash
        
        gdisk -l $1 > /tmp/mount_image.tmp
        
        let StartSector=`egrep "^   $2|^  $2" /tmp/mount_image.tmp | fmt -u -s | sed -e 's/^[ \t]*//' | head -1 | cut -d " " -f 2`

        let StartByte=($StartSector*512)

        echo "Mounting partition $2, which begins at sector $StartSector"

        mount -o loop,offset=$StartByte $1 $3

        rm /tmp/mount_image.tmp

        Save the script as, say, mount_image and use it like this:

        ./mount_image ~/image.img 2 /mnt

        This will mount partition 2 of image.img to /mnt. Note that the script relies on GPT fdisk (gdisk), which most
        distributions include in a package called gptfdisk or gdisk.
        In the long run, a better solution is to find a way to connect the disk that won't do the sector-size translation.
        A direct connection to a new motherboard should do the trick; or you can probably find an external enclosure that
        doesn't do the translation. In fact, some enclosures do the translation on USB ports but not on eSATA ports, so if
        your enclosure has an eSATA port, you could try using that. I realize that these solutions are all likely to cost
        money, which you say you don't have, but maybe you can trade your translating enclosure for one that doesn't do the
        translation.
        Another option that occurs to me is to try using a virtual machine like VirtualBox. Such a tool might assume a
        512-byte sector size when accessing the disk device, effectively undoing the translation; or you might be able
        to copy the disk's contents raw (as in dd if=/dev/sdc of=/dev/sdb) within the virtual machine, which might copy
        the contents with compression, thus enabling the image to fit on less disk space than the original consumes.

---You want to send large files from or to an embedded environment
    Solution: http://www.screenage.de/blog/2007/12/30/using-netcat-and-tar-for-network-file-transfer/
        The sender has to call netcat in server mode and pipe content into it. The next line tells tar
        to build a tarball and write it to standard output which is redirected via a pipe to netcat.
        Netcat is told to start in server mode (-l), listen on port 7878 (-p 7878) and shutdown itself
        after waiting 10 seconds after having seen an end of file in standard input (-q 10):

        $ tar c directory | nc -q 10 -l -p 7878

        The receiver has to call netcat and tell him to connect to the remote machine and the correct
        port and redirects the standard output to a file. For convenience he also sets a timeout
        parameter (-w 10):

        $ nc -w 10 remotehost 7878 > nameoftar.tar

        That’s all. You just setup a very fast file transfer. For testing purposes use localhost.
        Please note that on the receiver side you are completely free to choose a file name for
        the .tar file. If you use something like gzip or bzip2 compression you should choose
        something like .tar.gz or .tar.bz2 of course.
        
        https://www.ostechnix.com/quickly-transfer-large-files-network-linux-unix/
        
        On destination system:

        nc -l 7000 | pv | tar -xpf -

        On source system:

        tar -cf - * | pv | nc 192.168.1.105 7000

        Again, these commands should be run as root user. And, both source and destination systems
        should have netcat and pv installed. Transferring large files over LAN using netcat and tar
        can indeed save a lot of time.

        Disclaimer: There is no security in this method. Because, as you see in the above example,
        there is no authentication either side. All you need to know the destination system’s IP address.
        Transferring files using netcat is recommended only in protected networks. If you concern about
        security, I strongly suggest you to use scp command.

        https://wiki.openwrt.org/doc/howto/http.netcat
        
        As default OpenWrt installs

        busybox-ash (that is the Busybox-fork of the Debian implementation of the Almquist shell
        (see → http://www.in-ulm.de/~mascheck/various/ash/#busybox). In case you want to read about it.)
        busybox-nc (= the busybox implementation of netcat) does not support server mode.

        You can anytime replace those packages by they original counterparts:

        opkg install bash netcat

        Examples:

        https://forum.openwrt.org/viewtopic.php?pid=210001#p210001

        while true; do { echo -e 'HTTP/1.1 200 OK\r\n'; cat /tmp/index.html; } | netcat -l -p 8080; done

        My secure working set of commands:
        
        Sender OpenWrt
        
        opkg update && opkg install bash netcat nano
        nano /etc/firewall.user
            iptables -A input_rule -p tcp -s 192.168.1.Computer/32 --dport 7878 -j ACCEPT
            iptables -A input_rule -p tcp -s 0.0.0.0/0 --dport 7878 -j DROP
        save exit
        exit
        login
        tar c /storage/folder/ | nc -l -p 7878
        
        Receiver Computer
        
        su -
        apt install -y netcat pv
        exit
        nc 192.168.1.Openrt 7878 | pv | tar -xpf -
        
        Used 1,3 MB of RAM on OpenWrt with 2.8MB transfer speed limited by router cpu power.
        http://g33kinfo.com/info/archives/1713

---You see message  tar: removing leading '/' from member names
    Solution: https://unix.stackexchange.com/questions/59243/tar-removing-leading-from-member-names#59246
        That's actually a feature, not a problem. Archives with absolute locations are a security risk.
        Attackers could use such archives to trick users into installing files in critical system locations.
        Yes, you could use -P. But what's wrong with allowing tar to remove the forward slash, and simply
        requiring the user of the archive to explicitly do the extraction in the root directory? Then
        they're consciously impacting critical system locations, and can't do it by accident.
        Sometimes features are problems. I found this thread after setting up a backup script that would
        email on a non-zero exit status from tar. This particular message was causing tar to exit with a
        status of 1, which was causing me to receive false email alerts on successful backups, simply
        because tar was writing this message to STDERR. I fixed this issue by using my own solution:

        cd /path/to/network/share && tar -cJf scripts.backup.tar.xz -C / home/user/scripts 2>/dev/null || [send an email alert]

        If you want to get rid of "Removing leading `/' from member names" being printed to STDERR, but
        still want to leave off those leading slashes as tar wisely does by default, I saw an excellent
        solution here by commenter timsoft.
        The solution involves using -C option to change directory to the root (/), then specifying the file
        tree to archive without a leading slash, because now you only need a relative path. This does the same
        thing as a normal tar create command, but no stripping is needed:

        tar fcz bkup.tar.gz -C / home/foo/

        Doesn't work if you want to tar files denoted by shell-expansion (e.g. tar c -C / home/foo/*), because
        the shell doesn't know about the changed root.
        I found the most appropriate solution for my case (in a shell script) is to go to the parent directory
        and execute the command there.

        cd /var/www/
        tar -czf mysite.gz mysite

        Instead of:

        tar -czf /var/www/mysite.gz /var/www/mysite


#### TODO

-add more concise stuff
-when it seems complete convert to Libre Office document and export as PDF
-continue adding stuff and fixing existing stuff for a new edition or new Debian version
